{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Collection: Building an Instagram Crawler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this walkthrough we will see how we can crawl data from Instagram using the Selenium WebDriver."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Set up the WebDriver\n",
    "\n",
    "The first thing we need is a web driver. A web driver is basically a browser that can be controlled programatically."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# Set up a function to start the webdriver\n",
    "from selenium import webdriver\n",
    "def start_webdriver():\n",
    "    chromedriver_path = 'helpers/chromedriver'\n",
    "    driver = webdriver.Chrome(chromedriver_path)\n",
    "    return driver"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# Execute the webdriver\n",
    "driver = start_webdriver()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Navigate to Instagram and Login\n",
    "In order to log in we need to mimic the same user flow that we would use to log on manually. To do so, we use the Google Developer Tools to find the selectors / clases of the respective buttons and form fields."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "driver.get(\"https://www.instagram.com/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Import packages that we need\n",
    "from random import randint\n",
    "import time\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# Define Login Helper Function\n",
    "def login():\n",
    "  try:\n",
    "    # the login_info.json file contains the login information for five different Instagram accounts. We randomly pick one of the five accounts and save the username and password in respective variables.\n",
    "    with open('helpers/login_info.json') as f:\n",
    "        login_info = json.load(f)\n",
    "    random_number = randint(0, len(login_info['accounts']) - 1)\n",
    "    user = login_info['accounts'][random_number]['username']\n",
    "    pw = login_info['accounts'][random_number]['pw']\n",
    "    # We go to the Instagram home page\n",
    "    driver.get(\"https://www.instagram.com/\")\n",
    "    # We wait five seconds in order to make sure the page has fully loaded\n",
    "    time.sleep(5)\n",
    "    # We programmatically close the cookie notice\n",
    "    try:\n",
    "      driver.find_element_by_css_selector('.aOOlW').click()\n",
    "    except:\n",
    "      pass\n",
    "    time.sleep(3)\n",
    "    # We find the username and password fields and make sure they are empty\n",
    "    username = driver.find_element_by_css_selector(\"input[name='username']\")\n",
    "    password = driver.find_element_by_css_selector(\"input[name='password']\")\n",
    "    username.clear()\n",
    "    password.clear()\n",
    "    # We enter the login credentials into the form and then programmatically click the login button.\n",
    "    username.send_keys(user)\n",
    "    password.send_keys(pw)\n",
    "    time.sleep(randint(3,5))\n",
    "    login = driver.find_element_by_css_selector(\"button[type='submit']\").click()\n",
    "  except:\n",
    "    print(\"Could not log in / already logged in\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Define Logout Helper Function\n",
    "def logout():\n",
    "  try:\n",
    "    # We go to the Instagram home page\n",
    "    driver.get(\"https://www.instagram.com/\")\n",
    "    time.sleep(5)\n",
    "    # We open the dropdown menu\n",
    "    menu = driver.find_element_by_class_name(\"_47KiJ\")\n",
    "    menu.find_element_by_class_name(\"_2dbep\").click()\n",
    "    time.sleep(3)\n",
    "    # We click on the logout button\n",
    "    menu.find_element_by_css_selector('.-qQT3:last-child').click()\n",
    "    time.sleep(1)\n",
    "    # We delete all cookies so that Instagram does not \n",
    "    # modify the login process when we want to log in again\n",
    "    driver.delete_all_cookies()\n",
    "  except:\n",
    "    print(\"Could not log out / already logged out\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Execute Login Helper Function\n",
    "login()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# Execute Logout Helper Function\n",
    "logout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Decide which Accounts / Companies to Crawl and Create a Folder for Each"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# For this tutorial we take three big FMCG brands as an example\n",
    "companies = ['nestle', 'unilever', 'proctergamble']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# Import the os package\n",
    "import os\n",
    "# Define function that checks if a folder for the company exists within the example data folder. If not, it creates one.\n",
    "def create_company_folder(company):\n",
    "  path = os.getcwd() + \"/example_data/\" + company + \"/\"\n",
    "  if not os.path.exists(path):\n",
    "      os.makedirs(path)\n",
    "  return path\n",
    "# Execute the function\n",
    "for company in companies:\n",
    "  create_company_folder(company)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# Check out one of the accounts to plan the next steps\n",
    "driver.get(\"https://www.instagram.com/\" + companies[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Get Post URLs\n",
    "In order to crawl the content of all Instagram posts of the selected accounts, we need their respective URLs. We get these by programatically scrolling to the bottom of the page and saving the URLs (href-attribute of the pictures) after every scroll action.\n",
    "\n",
    "For this tutorial we limit the number of scrolled posts to 100 per company."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "#check if hrefs.txt file already exists in the folder\n",
    "from pathlib import Path\n",
    "def find_hrefs(company):\n",
    "    # Define the file in which all URLs will be saved in the end\n",
    "    href_file = os.getcwd() + \"/example_data/\" + company + \"/hrefs.txt\"\n",
    "    # Check if the file already exists\n",
    "    href_file_exists = Path(href_file).is_file()\n",
    "    # if the file does not exist, start scraping the URLs\n",
    "    if not href_file_exists:\n",
    "        print(\"no URLs found for \" + company + \", starting to scrape them\")\n",
    "        time.sleep(randint(3, 5))\n",
    "        # Go to the company's Instagram account\n",
    "        driver.get(\"https://www.instagram.com/\" + company)\n",
    "        # Scrape all URLs, then scroll down and scrape the newly loaded posts until the end of the page is reached\n",
    "        # For this tutorial we also limit the number of scrolled posts to 100 per company\n",
    "        hrefs = []\n",
    "        scrolldown = 0\n",
    "        match = False\n",
    "        while (match == False and len(hrefs) < 100):\n",
    "            last_count = scrolldown\n",
    "            # Find all links that are currently displayed on the page\n",
    "            links = driver.find_elements_by_tag_name('a')\n",
    "            time.sleep(randint(3, 4))\n",
    "            for link in links:\n",
    "                try:\n",
    "                    href = link.get_attribute('href')\n",
    "                    # only take links that include \"/p/\", indicating that it is a post link\n",
    "                    if '/p/' in href:\n",
    "                        # only add the post to the list of URLs if it is not in the list yet (prevent duplicates)\n",
    "                        if href not in hrefs:\n",
    "                            if len(hrefs) < 100:\n",
    "                                hrefs.append(href)\n",
    "                except:\n",
    "                    pass\n",
    "            # scroll to the bottom of the page to load new posts\n",
    "            scrolldown = driver.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight);var scrolldown=document.body.scrollHeight;return scrolldown;\")\n",
    "            # stop the process when the end of the page is reached or we have collected at least 100 URLs\n",
    "            if last_count == scrolldown and len(hrefs) == 100:\n",
    "                match = True\n",
    "        print(\"saving \" + str(len(hrefs)) + \" URLs to file for \" + company)\n",
    "        with open(href_file, 'w') as file:\n",
    "            file.write(str(hrefs))\n",
    "    else:\n",
    "        print(\"URLs file discovered for \" + company)\n",
    "        file = open(href_file, 'r')\n",
    "        hrefs = eval(file.read())\n",
    "    return hrefs, href_file_exists"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# Execute the Scraping Function, iterating over the companies\n",
    "for company in companies:\n",
    "  find_hrefs(company)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "no URLs found for nestle, starting to scrape them\n",
      "saving 100 URLs to file for nestle\n",
      "URLs file discovered for unilever\n",
      "URLs file discovered for proctergamble\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Iterate over the URLs and save post data as raw .json-files\n",
    "Fortunately, we can leverage the Instagram GraphQL API to retrieve posts as structured data (otherwise we would have to go through all the different HTML elements that contain the information we need and scrape it from there). To retrieve a post as structured data we just add \"?__a=1\" to the URL. This yields a .json (Javascript Object Notation) file that we can save to our harddrive.\n",
    "\n",
    "There is a caveat: images are only saved as URLs. However, Instagram periodically changes image URLs. Therefore, we need to save the images on our own harddrive or some other service (see next steps)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# define function that iterates over URLs and save json files\n",
    "def save_post_data(company):\n",
    "    href_file = os.getcwd() + \"/example_data/\" + company + \"/hrefs.txt\"\n",
    "    file = open(href_file, 'r')\n",
    "    hrefs = eval(file.read())\n",
    "    counter = 0\n",
    "    while counter < 100:\n",
    "        href = hrefs[counter]\n",
    "        # get the post ID from the URL\n",
    "        post_id = os.path.basename(os.path.normpath(href))\n",
    "        # define the file name\n",
    "        json_file = os.getcwd() + \"/example_data/\" + company + \"/\" + post_id + \".json\"\n",
    "        # navigate to the structured data of the post and save it as json file\n",
    "        if not Path(json_file).is_file():\n",
    "            time.sleep(randint(2, 5))\n",
    "            href_url = href + \"?__a=1\"\n",
    "            driver.get(href_url)\n",
    "            post_data = json.loads(driver.find_element_by_tag_name('body').text)\n",
    "            with open(json_file, 'w', encoding=\"utf-8\") as file:\n",
    "                json.dump(post_data, file)\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            counter = counter + 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# execute the function\n",
    "for company in companies:\n",
    "  save_post_data(company)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6: Aggregate the data into a CSV file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "def get_data_from_json(path):\n",
    "    with open(path) as f:\n",
    "        post_data = json.load(f)\n",
    "    \n",
    "    post = post_data['graphql']['shortcode_media']\n",
    "    \n",
    "    try:\n",
    "        post_description = post[\"edge_media_to_caption\"][\"edges\"][0][\"node\"][\"text\"]\n",
    "    except:\n",
    "        post_description = \"\"\n",
    "        \n",
    "    try:\n",
    "        accessibility_caption = post[\"edge_media_to_caption\"][\"accessibility_caption\"]\n",
    "    except:\n",
    "        accessibility_caption = None\n",
    "\n",
    "    try:\n",
    "        location = post[\"location\"][\"name\"]\n",
    "    except:\n",
    "        location = \"\"\n",
    "    \n",
    "    try:\n",
    "        comments = post[\"edge_media_to_parent_comment\"][\"edges\"]\n",
    "    except:\n",
    "        comments = []\n",
    "\n",
    "    try:\n",
    "        carousel = post[\"edge_sidecar_to_children\"][\"edges\"]\n",
    "        images = []\n",
    "        for image in carousel:\n",
    "            images.append({\n",
    "                \"url\": image[\"node\"][\"display_url\"]\n",
    "            })\n",
    "    except:\n",
    "        images = [\n",
    "            {\n",
    "            \"url\": post[\"display_url\"]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    posting = {\n",
    "        \"shortcode\": post[\"shortcode\"],\n",
    "        \"images\": images,\n",
    "        \"company\": post[\"owner\"][\"username\"],\n",
    "        \"post_id\": post[\"id\"],\n",
    "        \"date\": post[\"edge_media_preview_like\"][\"count\"],\n",
    "        \"post_description\": post_description,\n",
    "        \"accessibility_caption\": accessibility_caption,\n",
    "        \"count_likes\": post[\"edge_media_preview_like\"][\"count\"],\n",
    "        \"count_comments\": post[\"edge_media_to_parent_comment\"][\"count\"],\n",
    "        \"location\": location,\n",
    "        \"comments_disabled\": post[\"comments_disabled\"],\n",
    "        \"is_ad\": post[\"is_ad\"],\n",
    "        \"is_video\": post[\"is_video\"] \n",
    "    }\n",
    "    \n",
    "    comments = []\n",
    "    answers = []\n",
    "    \n",
    "    comments_raw = post[\"edge_media_to_parent_comment\"][\"edges\"]\n",
    "    for comment in comments_raw:\n",
    "        comment = comment[\"node\"]\n",
    "        comments.append({\n",
    "            \"id\": comment[\"id\"],\n",
    "            \"text\": comment[\"text\"],\n",
    "            \"author\": comment[\"owner\"][\"username\"],\n",
    "            \"created_at\": comment[\"created_at\"],\n",
    "            \"count_likes\": comment[\"edge_liked_by\"][\"count\"],\n",
    "            \"count_answers\": comment[\"edge_threaded_comments\"][\"count\"],\n",
    "            \"report_as_spam\": comment[\"did_report_as_spam\"],\n",
    "            \"post\": post[\"shortcode\"]\n",
    "        })\n",
    "        \n",
    "        answers_raw = comment[\"edge_threaded_comments\"][\"edges\"]\n",
    "        for answer in answers_raw:\n",
    "            answer = answer[\"node\"]\n",
    "            answers.append({\n",
    "                \"id\": answer[\"id\"],\n",
    "                \"text\": answer[\"text\"],\n",
    "                \"author\": answer[\"owner\"][\"username\"],\n",
    "                \"created_at\": answer[\"created_at\"],\n",
    "                \"count_likes\": answer[\"edge_liked_by\"][\"count\"],\n",
    "                \"report_as_spam\": answer[\"did_report_as_spam\"],\n",
    "                \"comment\": comment[\"id\"],\n",
    "                \"comment_text\": comment[\"text\"],\n",
    "                \"post\": post[\"shortcode\"]\n",
    "            })\n",
    "        \n",
    "    \n",
    "    return posting, comments, answers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "def iterate_over_jsons():\n",
    "    postings = []\n",
    "    comments = []\n",
    "    answers = []\n",
    "\n",
    "    for company in companies:\n",
    "        folder_path = os.getcwd() + \"/example_data/\" + company + \"/\"\n",
    "        files = [f for f in os.listdir(folder_path)]\n",
    "        files.remove('hrefs.txt')\n",
    "        for file in files:\n",
    "            file_path = folder_path + file\n",
    "            p, c, a = get_data_from_json(file_path)\n",
    "            postings.append(p)\n",
    "            comments = comments + c\n",
    "            answers = answers + a\n",
    "    return postings, comments, answers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "postings, comments, answers = iterate_over_jsons()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "postings_df = pd.DataFrame(postings).set_index(\"shortcode\")\n",
    "postings_df.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>company</th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>post_description</th>\n",
       "      <th>accessibility_caption</th>\n",
       "      <th>count_likes</th>\n",
       "      <th>count_comments</th>\n",
       "      <th>location</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>is_ad</th>\n",
       "      <th>is_video</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMhBzBMAaJY</th>\n",
       "      <td>[{'url': 'https://scontent-zrh1-1.cdninstagram...</td>\n",
       "      <td>nestle</td>\n",
       "      <td>2531312369573929560</td>\n",
       "      <td>344</td>\n",
       "      <td>2020 highlighted the strength of the human-pet...</td>\n",
       "      <td>None</td>\n",
       "      <td>344</td>\n",
       "      <td>82</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMSLVR1AiB0</th>\n",
       "      <td>[{'url': 'https://scontent-zrh1-1.cdninstagram...</td>\n",
       "      <td>nestle</td>\n",
       "      <td>2527132181671846004</td>\n",
       "      <td>936</td>\n",
       "      <td>In Pakistan, we‚Äôre helping over 1,500 women ca...</td>\n",
       "      <td>None</td>\n",
       "      <td>936</td>\n",
       "      <td>2499</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTwRr8lMW4g</th>\n",
       "      <td>[{'url': 'https://scontent-zrh1-1.cdninstagram...</td>\n",
       "      <td>nestle</td>\n",
       "      <td>2661705166552657440</td>\n",
       "      <td>398</td>\n",
       "      <td>Do you know the 5 innovations our experts have...</td>\n",
       "      <td>None</td>\n",
       "      <td>398</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        images company  \\\n",
       "shortcode                                                                \n",
       "CMhBzBMAaJY  [{'url': 'https://scontent-zrh1-1.cdninstagram...  nestle   \n",
       "CMSLVR1AiB0  [{'url': 'https://scontent-zrh1-1.cdninstagram...  nestle   \n",
       "CTwRr8lMW4g  [{'url': 'https://scontent-zrh1-1.cdninstagram...  nestle   \n",
       "\n",
       "                         post_id  date  \\\n",
       "shortcode                                \n",
       "CMhBzBMAaJY  2531312369573929560   344   \n",
       "CMSLVR1AiB0  2527132181671846004   936   \n",
       "CTwRr8lMW4g  2661705166552657440   398   \n",
       "\n",
       "                                              post_description  \\\n",
       "shortcode                                                        \n",
       "CMhBzBMAaJY  2020 highlighted the strength of the human-pet...   \n",
       "CMSLVR1AiB0  In Pakistan, we‚Äôre helping over 1,500 women ca...   \n",
       "CTwRr8lMW4g  Do you know the 5 innovations our experts have...   \n",
       "\n",
       "            accessibility_caption  count_likes  count_comments location  \\\n",
       "shortcode                                                                 \n",
       "CMhBzBMAaJY                  None          344              82            \n",
       "CMSLVR1AiB0                  None          936            2499            \n",
       "CTwRr8lMW4g                  None          398               2            \n",
       "\n",
       "             comments_disabled  is_ad  is_video  \n",
       "shortcode                                        \n",
       "CMhBzBMAaJY              False  False      True  \n",
       "CMSLVR1AiB0              False  False     False  \n",
       "CTwRr8lMW4g              False  False     False  "
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "comments_df = pd.DataFrame(comments).set_index(\"id\")\n",
    "comments_df.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>count_likes</th>\n",
       "      <th>count_answers</th>\n",
       "      <th>report_as_spam</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18200756470003696</th>\n",
       "      <td>Please, don't sponsor belarusian dictatorü§ç‚ù§Ô∏èü§ç</td>\n",
       "      <td>lee_sarko</td>\n",
       "      <td>1616013475</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CMhBzBMAaJY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876003864289688</th>\n",
       "      <td>Nestl√©, please stop sponsoring the Lukashenka ...</td>\n",
       "      <td>ogo.by</td>\n",
       "      <td>1616013519</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CMhBzBMAaJY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17905891759742854</th>\n",
       "      <td>Please stop ignoring comments!</td>\n",
       "      <td>pro.otdyh</td>\n",
       "      <td>1616014005</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CMhBzBMAaJY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17886434645021066</th>\n",
       "      <td>You steal water, use slavery and child labour,...</td>\n",
       "      <td>asymptotax</td>\n",
       "      <td>1616014415</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CMhBzBMAaJY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18199387912033928</th>\n",
       "      <td>As I see Nestle on Lukashenko's TV, no more Ne...</td>\n",
       "      <td>maks.zakharau</td>\n",
       "      <td>1616018307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>CMhBzBMAaJY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                text  \\\n",
       "id                                                                     \n",
       "18200756470003696      Please, don't sponsor belarusian dictatorü§ç‚ù§Ô∏èü§ç   \n",
       "17876003864289688  Nestl√©, please stop sponsoring the Lukashenka ...   \n",
       "17905891759742854                     Please stop ignoring comments!   \n",
       "17886434645021066  You steal water, use slavery and child labour,...   \n",
       "18199387912033928  As I see Nestle on Lukashenko's TV, no more Ne...   \n",
       "\n",
       "                          author  created_at  count_likes  count_answers  \\\n",
       "id                                                                         \n",
       "18200756470003696      lee_sarko  1616013475            5              0   \n",
       "17876003864289688         ogo.by  1616013519            8              0   \n",
       "17905891759742854      pro.otdyh  1616014005           10              0   \n",
       "17886434645021066     asymptotax  1616014415            2              0   \n",
       "18199387912033928  maks.zakharau  1616018307            3              0   \n",
       "\n",
       "                   report_as_spam         post  \n",
       "id                                              \n",
       "18200756470003696           False  CMhBzBMAaJY  \n",
       "17876003864289688           False  CMhBzBMAaJY  \n",
       "17905891759742854           False  CMhBzBMAaJY  \n",
       "17886434645021066           False  CMhBzBMAaJY  \n",
       "18199387912033928           False  CMhBzBMAaJY  "
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "answers_df = pd.DataFrame(answers).set_index(\"id\")\n",
    "answers_df.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>count_likes</th>\n",
       "      <th>report_as_spam</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17871699620348519</th>\n",
       "      <td>@igs_wijaya Hi, please know that tackling plas...</td>\n",
       "      <td>nestle</td>\n",
       "      <td>1621234593</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>17925167515608531</td>\n",
       "      <td>Biggest pollutant</td>\n",
       "      <td>COx11GkLDUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17963515711414212</th>\n",
       "      <td>@nestle @greenpeace @greenpeaceid</td>\n",
       "      <td>igs_wijaya</td>\n",
       "      <td>1621241505</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>17925167515608531</td>\n",
       "      <td>Biggest pollutant</td>\n",
       "      <td>COx11GkLDUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17900352358979841</th>\n",
       "      <td>@nestle and that's why you guys continue to pu...</td>\n",
       "      <td>cherry_jubilee33</td>\n",
       "      <td>1621353219</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>17925167515608531</td>\n",
       "      <td>Biggest pollutant</td>\n",
       "      <td>COx11GkLDUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                text  \\\n",
       "id                                                                     \n",
       "17871699620348519  @igs_wijaya Hi, please know that tackling plas...   \n",
       "17963515711414212                  @nestle @greenpeace @greenpeaceid   \n",
       "17900352358979841  @nestle and that's why you guys continue to pu...   \n",
       "\n",
       "                             author  created_at  count_likes  report_as_spam  \\\n",
       "id                                                                             \n",
       "17871699620348519            nestle  1621234593            1           False   \n",
       "17963515711414212        igs_wijaya  1621241505            0           False   \n",
       "17900352358979841  cherry_jubilee33  1621353219            2           False   \n",
       "\n",
       "                             comment       comment_text         post  \n",
       "id                                                                    \n",
       "17871699620348519  17925167515608531  Biggest pollutant  COx11GkLDUB  \n",
       "17963515711414212  17925167515608531  Biggest pollutant  COx11GkLDUB  \n",
       "17900352358979841  17925167515608531  Biggest pollutant  COx11GkLDUB  "
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "postings_df.to_csv(\"postings.csv\")\n",
    "comments_df.to_csv(\"comments.csv\")\n",
    "answers_df.to_csv(\"answers.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 7: Export the data to Airtable for manual coding of images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "from Naked.toolshed.shell import execute, execute_js, muterun_js\n",
    "for company in companies:\n",
    "  execute('node airtable/airtable.js ' + company)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nestle\n",
      "[]\n",
      "recDemBQxeLqFYWzc\n",
      "recQeX80OYJ21CXL7\n",
      "reciDXel0yYaWf8Ro\n",
      "recYT7vqs50xUHeNh\n",
      "rec5z7K7hY17i4jNY\n",
      "recrwtkBpXV2UHTii\n",
      "recAng7QSx2RKsjeh\n",
      "recy1qT9BsxgUxyOV\n",
      "recZECMKnizJI4u6k\n",
      "recXSj0hgrmJ7Pxdv\n",
      "recFVZUKlUZMWno4p\n",
      "recKoM6j5cRqc0Fix\n",
      "rec0CQaeCvLgtypQX\n",
      "reczIcXQNjFk7A7HB\n",
      "recO2TatF3dIreULJ\n",
      "recdUlq1Z0yoO0T8B\n",
      "recG2FhKimPYwwfZ3\n",
      "recJ8lPD8PJqthTsq\n",
      "recQRpvbw7yCN7nZw\n",
      "rechpfER1dRR1nXjf\n",
      "recG8IVAyTpErpfok\n",
      "recAshBRuZWuvZHtZ\n",
      "recg4sPfQKN4Hl48H\n",
      "rec1RRBPguPYd8zdK\n",
      "recQ2POOGsK6PCPdX\n",
      "recR38uXgaChPQSeE\n",
      "recqOf1vFqQldDmUm\n",
      "recPSd3xwTiZY9ftb\n",
      "rec7dYrjR2Tv59Vb8\n",
      "rec0R4Q3vXCL94xLs\n",
      "recdGAogvqToClHHn\n",
      "rec1iUrIRPTzaU18g\n",
      "recnQWntVgzaK9CsL\n",
      "recXvzPZyD7pn5kbg\n",
      "recYviScHpn72n1O7\n",
      "recxsYXxyRTbUK3Gp\n",
      "rec6MDu9ps18XWPRn\n",
      "recsp9IXphzEVZilA\n",
      "recEzyHfgbHmZvoYB\n",
      "recLbvn3t4BCyzSoi\n",
      "recWl49l5dkkMKm8s\n",
      "recoeU0QskFTeRmq3\n",
      "recaCkdh7RNeGXWVU\n",
      "recyyVIrxzbqNDKFI\n",
      "recIG5q8JMoyFzunv\n",
      "recaUjsjyZbVhe4Xk\n",
      "recMIbannqsgb2TB3\n",
      "rec5mERfShFN7oSOO\n",
      "recMIXlX6PCGLYSc8\n",
      "recdOtfqgMjYF9Plv\n",
      "rec8hJHNzXOIxRQax\n",
      "recxaVwdJoTFDliWz\n",
      "recAyf2UGE8hGCO5N\n",
      "rec3ZU7IpiukPoM3o\n",
      "rec6W1I0cPX0jjbzf\n",
      "rec7KFZHQ9KVkDlEO\n",
      "recyoHjYKWKFguVDh\n",
      "recRapfNnFCmmH0kj\n",
      "recNQ0eOaz7Dvrhg0\n",
      "rec8H8qpCQkmHYCO8\n",
      "recTdpE2U5eakvd9S\n",
      "recznPTSQgWSutcTo\n",
      "recIl7Q0sb37bbmfJ\n",
      "recZ0cywa5MLQqLpS\n",
      "recBWBMnDtkcLB0fI\n",
      "rec8Oqnk2N64oYD3w\n",
      "recO2sYydTOUKIOyu\n",
      "recXvN1pealheoeAv\n",
      "rec9lX8TSGKUbibwa\n",
      "recbOyjjaK6a4lsoF\n",
      "rechursIaRMZa0gKV\n",
      "recYu8MOCRbs4Newu\n",
      "recmaA0h9auS8Ut3U\n",
      "recRvCb6R8xMPDyWr\n",
      "recx5jVwp56c3HQsB\n",
      "rechLJ3uyNaHgQck0\n",
      "recJh87fUrzdiGtgB\n",
      "recf0pqJSXZe0cp5w\n",
      "recjBV1f4GhnxcY5y\n",
      "recZu8kK6jEsVRdgB\n",
      "recJlbn8TU6KJRASA\n",
      "recnNS0bqL6lmEq9z\n",
      "recQm8wUpOq8oHPUA\n",
      "recCj6LB9uuYWjbRG\n",
      "recWhecrPz004ZsMt\n",
      "recvv6sKEPQgH69dc\n",
      "reclB42oKzCMNMPbC\n",
      "recRqC8HrdMPdIPvS\n",
      "reciq1x4w9qu7Xzf8\n",
      "recok6pzEA5OkDM98\n",
      "reclJP7mypAAlAw4S\n",
      "recZgpgYkrEHPCtLH\n",
      "reca7AwlT8um2Ub97\n",
      "rec9pxOr3ngGu7GR3\n",
      "recq0eN4Q9SJ6IrU8\n",
      "recdXRCpvC6jc3iHD\n",
      "recuqikz4UREbUZe3\n",
      "rec8LKSXYopzbCi5z\n",
      "recHPsJLRtR7uYp9A\n",
      "rec9JbIQgzWOkKrkW\n",
      "unilever\n",
      "[]\n",
      "proctergamble\n",
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "44cf03960ceb7c4dae63840fdb07d1a636e2d44365fb83c3782c6fb7da7fa481"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}